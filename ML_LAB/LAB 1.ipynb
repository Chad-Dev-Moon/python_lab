{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89d6879-4424-420d-a754-ced149db92ff",
   "metadata": {},
   "source": [
    "# LAB 1 - document classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9341738-7fd1-43ec-ad49-c8e046a305a0",
   "metadata": {},
   "source": [
    "**Ques 1 :** Write a program to read a file and convert it into a vector of unique words based on term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a068ff31-3416-49fe-86ff-6537eef3b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ENTER FILE NAME:  document001.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing: 7\n",
      "computers: 6\n",
      "power: 4\n",
      "evolution: 2\n",
      "vacuum: 2\n",
      "machines: 2\n",
      "quantum: 2\n",
      "development: 2\n",
      "could: 2\n",
      "patterns: 2\n",
      "systems: 2\n",
      "simulating: 2\n",
      "fascinating: 1\n",
      "journey: 1\n",
      "radically: 1\n",
      "transformed: 1\n",
      "society: 1\n",
      "early: 1\n",
      "days: 1\n",
      "tubebased: 1\n",
      "todayâ€™s: 1\n",
      "cuttingedge: 1\n",
      "technologies: 1\n",
      "nothing: 1\n",
      "short: 1\n",
      "revolutionary: 1\n",
      "initially: 1\n",
      "were: 1\n",
      "large: 1\n",
      "roomsized: 1\n",
      "perform: 1\n",
      "only: 1\n",
      "basic: 1\n",
      "arithmetic: 1\n",
      "however: 1\n",
      "transistors: 1\n",
      "replaced: 1\n",
      "tubes: 1\n",
      "became: 1\n",
      "smaller: 1\n",
      "faster: 1\n",
      "more: 1\n",
      "reliable: 1\n",
      "advent: 1\n",
      "microprocessors: 1\n",
      "1970s: 1\n",
      "marked: 1\n",
      "beginning: 1\n",
      "personal: 1\n",
      "computer: 1\n",
      "era: 1\n",
      "bringing: 1\n",
      "homes: 1\n",
      "small: 1\n",
      "businesses: 1\n",
      "shift: 1\n",
      "paved: 1\n",
      "way: 1\n",
      "software: 1\n",
      "innovations: 1\n",
      "rise: 1\n",
      "internet: 1\n",
      "recent: 1\n",
      "years: 1\n",
      "advancements: 1\n",
      "artificial: 1\n",
      "intelligence: 1\n",
      "ai: 1\n",
      "machine: 1\n",
      "learning: 1\n",
      "driving: 1\n",
      "next: 1\n",
      "wave: 1\n",
      "today: 1\n",
      "can: 1\n",
      "analyze: 1\n",
      "vast: 1\n",
      "amounts: 1\n",
      "data: 1\n",
      "learn: 1\n",
      "make: 1\n",
      "decisions: 1\n",
      "autonomously: 1\n",
      "highperformance: 1\n",
      "hpc: 1\n",
      "now: 1\n",
      "capable: 1\n",
      "complex: 1\n",
      "weather: 1\n",
      "molecular: 1\n",
      "interactions: 1\n",
      "become: 1\n",
      "indispensable: 1\n",
      "tools: 1\n",
      "research: 1\n",
      "looking: 1\n",
      "ahead: 1\n",
      "holds: 1\n",
      "promise: 1\n",
      "solving: 1\n",
      "problems: 1\n",
      "currently: 1\n",
      "beyond: 1\n",
      "reach: 1\n",
      "classical: 1\n",
      "such: 1\n",
      "behavior: 1\n",
      "molecules: 1\n",
      "atomic: 1\n",
      "level: 1\n",
      "lead: 1\n",
      "breakthroughs: 1\n",
      "fields: 1\n",
      "like: 1\n",
      "medicine: 1\n",
      "materials: 1\n",
      "science: 1\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def file_to_term_frequency_vector(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) \n",
    "    words = text.split()\n",
    "\n",
    "    stopwords = {'a', 'an', 'the', 'of', 'for', 'has', 'have', 'been', 'in', 'on', 'to', \n",
    "                 'this', 'that', 'from', 'as', 'is', 'are', 'and', 'at', 'do', 'how', 'what', 'where', 'why', 'which'}\n",
    "\n",
    "    freq_dict = {}\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        if word in freq_dict:\n",
    "            freq_dict[word] += 1\n",
    "        else:\n",
    "            freq_dict[word] = 1\n",
    "\n",
    "    sorted_freq = dict(sorted(freq_dict.items(), key=lambda x: x[1], reverse=True)) # soert by highest freq\n",
    "    return sorted_freq\n",
    "\n",
    "file_path = input(\"ENTER FILE NAME: \")\n",
    "freq_vector = file_to_term_frequency_vector(file_path)\n",
    "\n",
    "for word, freq in freq_vector.items():\n",
    "    print(f'{word}: {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b8b57-81cc-4c79-8475-62a904d759a9",
   "metadata": {},
   "source": [
    "**Ques 2 :** Write a program to read multiple files and make a vector by taking 10 most frequent words for each document and make a vector of the frequent words in all n documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a684d205-baae-4ea4-9dc4-77c521c0e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarity Matrix:\n",
      "\n",
      "   |---D1---|---D2---|---D3---|\n",
      "D1  1.0000    0.6575    0.4952    \n",
      "D2  0.6575    1.0000    0.5312    \n",
      "D3  0.4952    0.5312    1.0000    \n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import math\n",
    "\n",
    "def file_to_term_frequency_vector(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "\n",
    "    stopwords = {'a', 'an', 'the', 'of', 'for', 'has', 'have', 'in', 'on', 'to', \n",
    "             'this', 'that', 'from', 'as', 'is', 'are'}\n",
    "\n",
    "    freq_dict = {}\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            continue\n",
    "        if word in freq_dict:\n",
    "            freq_dict[word] += 1\n",
    "        else:\n",
    "            freq_dict[word] = 1\n",
    "\n",
    "    sorted_freq = dict(sorted(freq_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_freq\n",
    "\n",
    "def get_top_words(freq_dict, top_n=10):\n",
    "    return list(freq_dict.keys())[:top_n]\n",
    "\n",
    "def build_vector(freq_dict, vocabulary):\n",
    "    return [freq_dict.get(word, 0) for word in vocabulary] # taking reference from vocab, find the word's frequency, if not found set to 0\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot = sum(a * b for a, b in zip(vec1, vec2)) # zipped the vectors(lists) together to combine ele at same posn -> then multiplied correspondingly\n",
    "    norm1 = math.sqrt(sum(a * a for a in vec1)) # magnitude -- easy\n",
    "    norm2 = math.sqrt(sum(b * b for b in vec2))\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return dot / (norm1 * norm2)\n",
    "\n",
    "# Action begins here\n",
    "\n",
    "file_paths = ['document001.txt', 'document002.txt', 'document003.txt']\n",
    "\n",
    "freq_dicts = [file_to_term_frequency_vector(path) for path in file_paths]\n",
    "\n",
    "top_words = []\n",
    "for freq in freq_dicts:\n",
    "    top_words.extend(get_top_words(freq, top_n=10))\n",
    "\n",
    "vocabulary = sorted(set(top_words)) # converted to set to remove duplicates\n",
    "\n",
    "vectors = [build_vector(freq, vocabulary) for freq in freq_dicts]\n",
    "\n",
    "n = len(file_paths)\n",
    "print(\"\\nCosine Similarity Matrix:\\n\")\n",
    "print(\"   |---D1---|---D2---|---D3---|\")\n",
    "for i in range(n):\n",
    "    print(f\"D{i+1}\", end='  ')\n",
    "    for j in range(n):\n",
    "        sim = cosine_similarity(vectors[i], vectors[j])\n",
    "        print(f\"{sim:.4f}\", end='    ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5e2ea-a48c-47bd-8c7f-ddc212b429ae",
   "metadata": {},
   "source": [
    "# Similarity Result\n",
    "- Doc1 and Doc2 : 65%\n",
    "- Doc1 and Doc3 : 49%\n",
    "- Doc2 and Doc3 : 53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262ce36-21d9-4037-94d2-6b2b9863a25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
